{"version":"https://jsonfeed.org/version/1","title":"Karthik Selvam","home_page_url":"https://karthikselvam.com/","feed_url":"https://ronaldsvilcins.com/feed.json","description":"","icon":"https://ronaldsvilcins.com/assets/apple-touch-icon.png","favicon":"https://ronaldsvilcins.com/assets/favicon.ico","expired":false,"author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"},"items":[{"id":"90b4bf1a507d052fbc6e42deed7475bef0d3aec9","title":"Understanding Keystores, Certificates, and How Secure Communication Works in Java Apps","summary":"2023","content_text":"If you’re a developer or engineer starting with Java applications, you’ve probably come across terms like keystore, certificate, private key, and truststore. These are crucial when setting up secure communication between your app and others using SSL/TLS.\nLet’s break down what these terms mean and how they fit together — no fancy jargon, just simple explanations.\nWhat Is a Keystore? # A keystore is a secure file that stores private keys and certificates your Java app needs to prove its identity and encrypt data.\nPrivate Key: A secret key only your app knows. Certificate: A public file that proves your app’s identity. Think of a keystore like a locked box where you keep your secret keys and ID cards safely.\nCommon File Types You’ll See # When dealing with certificates and keys, you might find files with these extensions:\nFile Extension What It Is Purpose .jks Java KeyStore file Stores your private keys and certificates securely .crt Certificate file Your public certificate that others use to verify you .key Private key file Your secret private key .req (CSR) Certificate Signing Request A request you send to a Certificate Authority (CA) to get a certificate .public Public key file (less common) Contains just the public key part How Does This Fit Into Secure Communication? # Imagine you want your Java app to communicate securely over HTTPS or TLS.\nGenerate a Private Key (.key)\nThis is your secret key that proves your identity.\nCreate a CSR (.req)\nA request you send to a trusted Certificate Authority (CA), containing your public key and info about your app.\nGet a Certificate (.crt) from the CA\nThe CA verifies you and issues a certificate, which is like an ID card signed by a trusted authority.\nImport the Private Key and Certificate into a Keystore (.jks)\nYour Java app uses this keystore to present its identity and encrypt communications.\nSharing Certificates with Other Apps # Your app’s private key is secret and never shared.\nYour app’s certificate (.crt) is shared with other apps or clients that want to communicate with you.\nOther apps import your .crt into their truststore, which is their list of trusted certificates. This lets them verify your app’s identity during the secure handshake. If your certificate is self-signed, clients need to manually add your .crt to their truststore. If your certificate is signed by a public CA, most clients already trust it automatically. What’s the Difference Between Self-Signed and CA-Signed Certificates? # Self-Signed Certificate CA-Signed Certificate You generate and sign your own certificate A trusted CA verifies your identity and signs your certificate Clients need to manually trust your certificate Clients trust it automatically because they trust the CA Often used for testing or internal apps Used for public websites and production systems Why Should You Care? # As a Staff Engineer or anyone responsible for system security, you’ll often:\nSet up or troubleshoot secure communication between services. Fix SSL/TLS errors caused by missing or untrusted certificates. Manage certificate renewals and updates. Help teams understand how certificates and keystores work together. Final Thoughts # Understanding keystores, certificates, and how they work in Java apps is essential for secure software development. The next step is practicing creating keystores, generating CSRs, importing certificates, and testing secure connections.\n","content_html":"\u003cp\u003eIf you’re a developer or engineer starting with Java applications, you’ve probably come across terms like \u003cstrong\u003ekeystore\u003c/strong\u003e, \u003cstrong\u003ecertificate\u003c/strong\u003e, \u003cstrong\u003eprivate key\u003c/strong\u003e, and \u003cstrong\u003etruststore\u003c/strong\u003e. These are crucial when setting up secure communication between your app and others using SSL/TLS.\u003c/p\u003e\n\u003cp\u003eLet’s break down what these terms mean and how they fit together — no fancy jargon, just simple explanations.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"what-is-a-keystore\"\u003eWhat Is a Keystore? \u003ca href=\"#what-is-a-keystore\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ekeystore\u003c/strong\u003e is a secure file that stores \u003cstrong\u003eprivate keys\u003c/strong\u003e and \u003cstrong\u003ecertificates\u003c/strong\u003e your Java app needs to prove its identity and encrypt data.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePrivate Key: A secret key only your app knows.\u003c/li\u003e\n\u003cli\u003eCertificate: A public file that proves your app’s identity.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThink of a keystore like a locked box where you keep your secret keys and ID cards safely.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"common-file-types-youll-see\"\u003eCommon File Types You’ll See \u003ca href=\"#common-file-types-youll-see\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWhen dealing with certificates and keys, you might find files with these extensions:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eFile Extension\u003c/th\u003e\n\u003cth\u003eWhat It Is\u003c/th\u003e\n\u003cth\u003ePurpose\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e.jks\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eJava KeyStore file\u003c/td\u003e\n\u003ctd\u003eStores your private keys and certificates securely\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e.crt\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eCertificate file\u003c/td\u003e\n\u003ctd\u003eYour public certificate that others use to verify you\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e.key\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ePrivate key file\u003c/td\u003e\n\u003ctd\u003eYour secret private key\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e.req\u003c/code\u003e (CSR)\u003c/td\u003e\n\u003ctd\u003eCertificate Signing Request\u003c/td\u003e\n\u003ctd\u003eA request you send to a Certificate Authority (CA) to get a certificate\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e.public\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ePublic key file (less common)\u003c/td\u003e\n\u003ctd\u003eContains just the public key part\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003chr\u003e\n\u003ch2 id=\"how-does-this-fit-into-secure-communication\"\u003eHow Does This Fit Into Secure Communication? \u003ca href=\"#how-does-this-fit-into-secure-communication\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eImagine you want your Java app to communicate securely over HTTPS or TLS.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eGenerate a Private Key (\u003ccode\u003e.key\u003c/code\u003e)\u003c/strong\u003e\u003cbr\u003e\nThis is your secret key that proves your identity.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eCreate a CSR (\u003ccode\u003e.req\u003c/code\u003e)\u003c/strong\u003e\u003cbr\u003e\nA request you send to a trusted Certificate Authority (CA), containing your public key and info about your app.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eGet a Certificate (\u003ccode\u003e.crt\u003c/code\u003e) from the CA\u003c/strong\u003e\u003cbr\u003e\nThe CA verifies you and issues a certificate, which is like an ID card signed by a trusted authority.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eImport the Private Key and Certificate into a Keystore (\u003ccode\u003e.jks\u003c/code\u003e)\u003c/strong\u003e\u003cbr\u003e\nYour Java app uses this keystore to present its identity and encrypt communications.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"sharing-certificates-with-other-apps\"\u003eSharing Certificates with Other Apps \u003ca href=\"#sharing-certificates-with-other-apps\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eYour app’s \u003cstrong\u003eprivate key is secret\u003c/strong\u003e and never shared.\u003c/p\u003e\n\u003cp\u003eYour app’s \u003cstrong\u003ecertificate (\u003ccode\u003e.crt\u003c/code\u003e) is shared\u003c/strong\u003e with other apps or clients that want to communicate with you.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOther apps import your \u003ccode\u003e.crt\u003c/code\u003e into their \u003cstrong\u003etruststore\u003c/strong\u003e, which is their list of trusted certificates.\u003c/li\u003e\n\u003cli\u003eThis lets them verify your app’s identity during the secure handshake.\u003c/li\u003e\n\u003cli\u003eIf your certificate is \u003cstrong\u003eself-signed\u003c/strong\u003e, clients need to manually add your \u003ccode\u003e.crt\u003c/code\u003e to their truststore.\u003c/li\u003e\n\u003cli\u003eIf your certificate is signed by a \u003cstrong\u003epublic CA\u003c/strong\u003e, most clients already trust it automatically.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"whats-the-difference-between-self-signed-and-ca-signed-certificates\"\u003eWhat’s the Difference Between Self-Signed and CA-Signed Certificates? \u003ca href=\"#whats-the-difference-between-self-signed-and-ca-signed-certificates\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eSelf-Signed Certificate\u003c/th\u003e\n\u003cth\u003eCA-Signed Certificate\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eYou generate and sign your own certificate\u003c/td\u003e\n\u003ctd\u003eA trusted CA verifies your identity and signs your certificate\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eClients need to manually trust your certificate\u003c/td\u003e\n\u003ctd\u003eClients trust it automatically because they trust the CA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eOften used for testing or internal apps\u003c/td\u003e\n\u003ctd\u003eUsed for public websites and production systems\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003chr\u003e\n\u003ch2 id=\"why-should-you-care\"\u003eWhy Should You Care? \u003ca href=\"#why-should-you-care\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAs a Staff Engineer or anyone responsible for system security, you’ll often:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSet up or troubleshoot secure communication between services.\u003c/li\u003e\n\u003cli\u003eFix SSL/TLS errors caused by missing or untrusted certificates.\u003c/li\u003e\n\u003cli\u003eManage certificate renewals and updates.\u003c/li\u003e\n\u003cli\u003eHelp teams understand how certificates and keystores work together.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"final-thoughts\"\u003eFinal Thoughts \u003ca href=\"#final-thoughts\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eUnderstanding keystores, certificates, and how they work in Java apps is essential for secure software development. The next step is practicing creating keystores, generating CSRs, importing certificates, and testing secure connections.\u003c/p\u003e\n","url":"https://karthikselvam.com/posts/2025/05/29/secure_comm/","image":"https://karthikselvam.com/photos/<no value>","banner_image":"https://karthikselvam.com/photos/<no value>","date_published":"29056-29-09T50:2929:00+00:00","date_modified":"29056-29-09T50:2929:00+00:00","author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"}},{"id":"942dd25f11aa40ca8143cf297dc0a9c9125b5279","title":"Understanding PostgreSQL’s Write-Ahead Logging (WAL)","summary":"2023","content_text":"PostgreSQL’s Write-Ahead Logging (WAL) is at the heart of its durability and crash recovery. If you’ve ever wondered how PostgreSQL ensures your data is safe—even in the event of a crash—this post will walk you through the architecture, flow, and the actual source code that makes it all work.\nHigh-Level Architecture \u0026amp; Flow of WAL # What is WAL? # WAL is a mechanism that ensures all changes to the database are first recorded in a log before being applied to the data files. This guarantees that, even if the system crashes, PostgreSQL can recover to a consistent state.\nKey Components # WAL Buffers:\nIn-memory buffers that temporarily hold WAL records before they’re written to disk. WAL Files:\nOn-disk files (in pg_wal/), typically 16MB each, storing the WAL records. WAL Writer Process:\nA background process that flushes WAL buffers to disk. Checkpointer:\nEnsures data files are consistent with WAL. Archiver:\nOptionally archives completed WAL segments for point-in-time recovery (PITR). Sequence of Events # Change Initiation:\nA transaction modifies data (e.g., an INSERT). WAL Record Creation:\nThe change is encoded as a WAL record in memory. WAL Buffering:\nThe WAL record is placed in the WAL buffers. WAL Flush:\nBefore a transaction commits, its WAL records are flushed to disk. WAL File Management:\nWAL files are rotated, archived, and recycled as needed. Crash Recovery:\nOn restart after a crash, WAL is replayed to bring the database to a consistent state. Mapping WAL to the PostgreSQL Source Code # Let’s walk through the main code files and functions for each component.\n1. WAL Record Creation # File: xlog.c Key Struct: XLogRecord Key Functions: XLogInsert(): Called whenever a change is made (e.g., tuple insert/update/delete). Constructs a WAL record and appends it to the WAL buffers. XLogRegisterData(), XLogRegisterBuffer(): Used by lower-level code to register data and buffers that should be included in the WAL record. 2. WAL Buffering and Flushing # File: xlog.c Key Struct: XLogCtlData (shared memory control structure for WAL) Key Functions: XLogWrite(): Flushes WAL buffers to disk. XLogFlush(): Ensures that WAL up to a certain point is safely on disk (called before commit). XLogBackgroundFlush(): Used by the WAL writer background process. 3. WAL Writer Process # File: walwriter.c Key Function: WalWriterMain(): Main loop for the WAL writer background process, periodically flushing WAL buffers. 4. WAL File Management # File: xlog.c Key Functions: XLogFileInit(), XLogFileOpen(), XLogFileClose(): Manage creation, opening, and closing of WAL segment files. XLogFileName(): Generates the filename for a given WAL segment. 5. Crash Recovery # File: xlog.c Key Function: StartupXLOG(): Main function for crash recovery; reads and replays WAL records. 6. Archiving # File: xlogarchive.c Key Functions: XLogArchiveNotify(), XLogArchiveCheckDone() Important Structs, Macros, and Configurations # XLogRecPtr: 64-bit pointer to a WAL location. XLogRecord: Struct representing a single WAL record. XLogCtlData: Shared memory structure for WAL state. Configuration Parameters (in postgresql.conf):\nwal_level wal_buffers wal_writer_delay archive_mode, archive_command max_wal_size, min_wal_size Step-by-Step Exploration # WAL Record Creation:\nStart in xlog.c with XLogInsert(). See how a WAL record is constructed and added to the buffer. Explore how XLogRegisterData() and XLogRegisterBuffer() are used to build the record.\nWAL Buffering and Flushing:\nFollow XLogWrite() and XLogFlush(). See how WAL buffers are managed and flushed to disk. Understand the role of XLogCtlData.\nWAL Writer Process:\nLook at WalWriterMain() in walwriter.c. See how the background process periodically flushes WAL.\nWAL File Management:\nExplore XLogFileInit(), XLogFileOpen(), etc. See how WAL files are created, opened, and rotated.\nCrash Recovery:\nStudy StartupXLOG(). See how WAL is replayed after a crash.\nConclusion # PostgreSQL’s WAL system is a robust, well-architected mechanism that ensures your data is safe and recoverable. By understanding both the high-level flow and the underlying source code, you gain insight into one of the most critical parts of PostgreSQL’s architecture.\n","content_html":"\u003cp\u003ePostgreSQL’s Write-Ahead Logging (WAL) is at the heart of its durability and crash recovery. If you’ve ever wondered how PostgreSQL ensures your data is safe—even in the event of a crash—this post will walk you through the architecture, flow, and the actual source code that makes it all work.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"high-level-architecture--flow-of-wal\"\u003eHigh-Level Architecture \u0026amp; Flow of WAL \u003ca href=\"#high-level-architecture--flow-of-wal\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"what-is-wal\"\u003eWhat is WAL? \u003ca href=\"#what-is-wal\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eWAL is a mechanism that ensures all changes to the database are first recorded in a log before being applied to the data files. This guarantees that, even if the system crashes, PostgreSQL can recover to a consistent state.\u003c/p\u003e\n\u003ch3 id=\"key-components\"\u003eKey Components \u003ca href=\"#key-components\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eWAL Buffers:\u003c/strong\u003e\u003cbr\u003e\nIn-memory buffers that temporarily hold WAL records before they’re written to disk.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWAL Files:\u003c/strong\u003e\u003cbr\u003e\nOn-disk files (in \u003ccode\u003epg_wal/\u003c/code\u003e), typically 16MB each, storing the WAL records.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWAL Writer Process:\u003c/strong\u003e\u003cbr\u003e\nA background process that flushes WAL buffers to disk.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCheckpointer:\u003c/strong\u003e\u003cbr\u003e\nEnsures data files are consistent with WAL.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eArchiver:\u003c/strong\u003e\u003cbr\u003e\nOptionally archives completed WAL segments for point-in-time recovery (PITR).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"sequence-of-events\"\u003eSequence of Events \u003ca href=\"#sequence-of-events\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eChange Initiation:\u003c/strong\u003e\u003cbr\u003e\nA transaction modifies data (e.g., an \u003ccode\u003eINSERT\u003c/code\u003e).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWAL Record Creation:\u003c/strong\u003e\u003cbr\u003e\nThe change is encoded as a WAL record in memory.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWAL Buffering:\u003c/strong\u003e\u003cbr\u003e\nThe WAL record is placed in the WAL buffers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWAL Flush:\u003c/strong\u003e\u003cbr\u003e\nBefore a transaction commits, its WAL records are flushed to disk.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWAL File Management:\u003c/strong\u003e\u003cbr\u003e\nWAL files are rotated, archived, and recycled as needed.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCrash Recovery:\u003c/strong\u003e\u003cbr\u003e\nOn restart after a crash, WAL is replayed to bring the database to a consistent state.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"mapping-wal-to-the-postgresql-source-code\"\u003eMapping WAL to the PostgreSQL Source Code \u003ca href=\"#mapping-wal-to-the-postgresql-source-code\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eLet’s walk through the main code files and functions for each component.\u003c/p\u003e\n\u003ch3 id=\"1-wal-record-creation\"\u003e1. WAL Record Creation \u003ca href=\"#1-wal-record-creation\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFile:\u003c/strong\u003e xlog.c\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKey Struct:\u003c/strong\u003e \u003ccode\u003eXLogRecord\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKey Functions:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eXLogInsert()\u003c/code\u003e: Called whenever a change is made (e.g., tuple insert/update/delete). Constructs a WAL record and appends it to the WAL buffers.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eXLogRegisterData()\u003c/code\u003e, \u003ccode\u003eXLogRegisterBuffer()\u003c/code\u003e: Used by lower-level code to register data and buffers that should be included in the WAL record.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"2-wal-buffering-and-flushing\"\u003e2. WAL Buffering and Flushing \u003ca href=\"#2-wal-buffering-and-flushing\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFile:\u003c/strong\u003e xlog.c\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKey Struct:\u003c/strong\u003e \u003ccode\u003eXLogCtlData\u003c/code\u003e (shared memory control structure for WAL)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKey Functions:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eXLogWrite()\u003c/code\u003e: Flushes WAL buffers to disk.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eXLogFlush()\u003c/code\u003e: Ensures that WAL up to a certain point is safely on disk (called before commit).\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eXLogBackgroundFlush()\u003c/code\u003e: Used by the WAL writer background process.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"3-wal-writer-process\"\u003e3. WAL Writer Process \u003ca href=\"#3-wal-writer-process\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFile:\u003c/strong\u003e walwriter.c\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKey Function:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eWalWriterMain()\u003c/code\u003e: Main loop for the WAL writer background process, periodically flushing WAL buffers.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"4-wal-file-management\"\u003e4. WAL File Management \u003ca href=\"#4-wal-file-management\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFile:\u003c/strong\u003e xlog.c\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKey Functions:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eXLogFileInit()\u003c/code\u003e, \u003ccode\u003eXLogFileOpen()\u003c/code\u003e, \u003ccode\u003eXLogFileClose()\u003c/code\u003e: Manage creation, opening, and closing of WAL segment files.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eXLogFileName()\u003c/code\u003e: Generates the filename for a given WAL segment.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"5-crash-recovery\"\u003e5. Crash Recovery \u003ca href=\"#5-crash-recovery\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFile:\u003c/strong\u003e xlog.c\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKey Function:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eStartupXLOG()\u003c/code\u003e: Main function for crash recovery; reads and replays WAL records.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"6-archiving\"\u003e6. Archiving \u003ca href=\"#6-archiving\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFile:\u003c/strong\u003e xlogarchive.c\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKey Functions:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eXLogArchiveNotify()\u003c/code\u003e, \u003ccode\u003eXLogArchiveCheckDone()\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"important-structs-macros-and-configurations\"\u003eImportant Structs, Macros, and Configurations \u003ca href=\"#important-structs-macros-and-configurations\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eXLogRecPtr\u003c/code\u003e\u003c/strong\u003e: 64-bit pointer to a WAL location.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eXLogRecord\u003c/code\u003e\u003c/strong\u003e: Struct representing a single WAL record.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eXLogCtlData\u003c/code\u003e\u003c/strong\u003e: Shared memory structure for WAL state.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eConfiguration Parameters (in \u003ccode\u003epostgresql.conf\u003c/code\u003e):\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ewal_level\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ewal_buffers\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ewal_writer_delay\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003earchive_mode\u003c/code\u003e, \u003ccode\u003earchive_command\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emax_wal_size\u003c/code\u003e, \u003ccode\u003emin_wal_size\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-by-step-exploration\"\u003eStep-by-Step Exploration \u003ca href=\"#step-by-step-exploration\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eWAL Record Creation:\u003c/strong\u003e\u003cbr\u003e\nStart in \u003ccode\u003exlog.c\u003c/code\u003e with \u003ccode\u003eXLogInsert()\u003c/code\u003e. See how a WAL record is constructed and added to the buffer. Explore how \u003ccode\u003eXLogRegisterData()\u003c/code\u003e and \u003ccode\u003eXLogRegisterBuffer()\u003c/code\u003e are used to build the record.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eWAL Buffering and Flushing:\u003c/strong\u003e\u003cbr\u003e\nFollow \u003ccode\u003eXLogWrite()\u003c/code\u003e and \u003ccode\u003eXLogFlush()\u003c/code\u003e. See how WAL buffers are managed and flushed to disk. Understand the role of \u003ccode\u003eXLogCtlData\u003c/code\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eWAL Writer Process:\u003c/strong\u003e\u003cbr\u003e\nLook at \u003ccode\u003eWalWriterMain()\u003c/code\u003e in \u003ccode\u003ewalwriter.c\u003c/code\u003e. See how the background process periodically flushes WAL.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eWAL File Management:\u003c/strong\u003e\u003cbr\u003e\nExplore \u003ccode\u003eXLogFileInit()\u003c/code\u003e, \u003ccode\u003eXLogFileOpen()\u003c/code\u003e, etc. See how WAL files are created, opened, and rotated.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eCrash Recovery:\u003c/strong\u003e\u003cbr\u003e\nStudy \u003ccode\u003eStartupXLOG()\u003c/code\u003e. See how WAL is replayed after a crash.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion \u003ca href=\"#conclusion\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003ePostgreSQL’s WAL system is a robust, well-architected mechanism that ensures your data is safe and recoverable. By understanding both the high-level flow and the underlying source code, you gain insight into one of the most critical parts of PostgreSQL’s architecture.\u003c/p\u003e\n\u003chr\u003e\n","url":"https://karthikselvam.com/posts/2025/05/22/postgres_wal/","image":"https://karthikselvam.com/photos/<no value>","banner_image":"https://karthikselvam.com/photos/<no value>","date_published":"22056-22-09T50:2222:00+00:00","date_modified":"22056-22-09T50:2222:00+00:00","author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"}},{"id":"2bb0ecdfd217ff1a1b46a4b8205d6b01d48f02e4","title":"Awesome Stuff","summary":"2023","content_text":"1. Engineering Blogs\n2. Java Packages with UML Diagrams\n3. Java Resources\n4. The Architecture of Open Source Applications\n5. System Design\n","content_html":"\u003cp\u003e\u003cstrong\u003e1. \u003ca href=\"https://github.com/kilimchoi/engineering-blogs\"\u003eEngineering Blogs\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. \u003ca href=\"https://www.falkhausen.de/index.html\"\u003eJava Packages with UML Diagrams\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. \u003ca href=\"https://github.com/hadign20/student-career-handbook/blob/master/domain-specific/a-deeper-understanding-of-java.md\"\u003eJava Resources\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4. \u003ca href=\"https://aosabook.org/en/\"\u003eThe Architecture of Open Source Applications\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e5. \u003ca href=\"https://books.dwf.dev/docs/system-design/c0\"\u003eSystem Design\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n","url":"https://karthikselvam.com/posts/2023/02/25/awesome_stuff/","image":"https://karthikselvam.com/photos/<no value>","banner_image":"https://karthikselvam.com/photos/<no value>","date_published":"25026-25-09T20:2525:00+00:00","date_modified":"25026-25-09T20:2525:00+00:00","author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"}},{"id":"0d76f1d072960250b22ed281f11c16b9618e7027","title":"Fundamentals of Multithreading","summary":"2023","content_text":"1. Thread creation : In Java, you can create a thread by either extending the Thread class or implementing the Runnable interface. Here\u0026rsquo;s how you can do it:\nExtending the Thread class: public class MyThread extends Thread { public void run() { // code to be executed in this thread } } You can create an instance of the MyThread class and start the thread using the start() method:\nMyThread myThread = new MyThread(); myThread.start(); Implementing the Runnable interface: public class MyRunnable implements Runnable { public void run() { // code to be executed in this thread } } You can create an instance of the MyRunnable class and pass it to a Thread object\u0026rsquo;s constructor:\nMyRunnable myRunnable = new MyRunnable(); Thread thread = new Thread(myRunnable); thread.start(); In both cases, the run() method contains the code that will be executed when the thread is started. You should not call the run() method directly, but rather use the start() method to start the thread.\n2. Thread Termination : Following are reasons to terminate a thread:\nThreads in a computer consume various resources, such as memory, kernel resources, CPU cycles, and cache memory.\nIf a thread finished its work, but the application is still running we want to clean up the thread\u0026rsquo;s resources.\nIf a thread is misbehaving, we want to stop it.\nThe application will not stop as long as at least one thread is still running.\nIn Java, you can terminate a thread by calling the interrupt() method on the thread object. This method sets a flag on the thread to indicate that it should stop executing. However, it is up to the thread\u0026rsquo;s code to check for the interrupt flag and terminate gracefully.\npublic class MyThread extends Thread { @Override public void run() { while (!Thread.currentThread().isInterrupted()) { // do some work } System.out.println(\u0026quot;Thread is terminating.\u0026quot;); } } public class Main { public static void main(String[] args) { MyThread thread = new MyThread(); thread.start(); // Interrupt the thread thread.interrupt(); } } In this example, the MyThread class extends the Thread class and overrides the run() method to do some work in a loop. Inside the loop, the thread checks if it has been interrupted using the isInterrupted() method.\nIn the Main class, we create an instance of MyThread and start it. When the interrupt() method is called, the isInterrupted() method in the MyThread class will return true, causing the thread to exit the loop and terminate gracefully.\n3. Daemon Threads : In Java, a daemon thread is a type of thread that runs in the background and does not prevent the Java Virtual Machine (JVM) from exiting when the program finishes execution.\nDaemon threads are typically used for tasks that need to run continuously in the background, such as garbage collection or other system-level tasks. They are also commonly used in server applications to perform tasks like cleaning up old connections or handling periodic maintenance tasks.\nTo create a daemon thread in Java, you can use the setDaemon() method on a Thread object. For example, the following code creates a new thread and sets it as a daemon thread:\nThread myThread = new Thread(new Runnable() { public void run() { // Do some background task here } }); myThread.setDaemon(true); myThread.start(); Once a thread is set as a daemon thread, you cannot change it back to a non-daemon thread.\n4. Joining Threads :\nJoining threads in Java is done using the join() method, which allows one thread to wait for another thread to complete before continuing. Here\u0026rsquo;s a simple example of how to use the join() method to join two threads:\npublic class JoinExample { public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -\u0026gt; { System.out.println(\u0026quot;Thread 1 is running\u0026quot;); try { Thread.sleep(2000); // simulate some work being done } catch (InterruptedException e) { System.out.println(\u0026quot;Thread 1 was interrupted\u0026quot;); } System.out.println(\u0026quot;Thread 1 is finished\u0026quot;); }); Thread t2 = new Thread(() -\u0026gt; { System.out.println(\u0026quot;Thread 2 is running\u0026quot;); try { Thread.sleep(1000); // simulate some work being done } catch (InterruptedException e) { System.out.println(\u0026quot;Thread 2 was interrupted\u0026quot;); } System.out.println(\u0026quot;Thread 2 is finished\u0026quot;); }); t1.start(); t2.start(); // wait for both threads to finish t1.join(); t2.join(); System.out.println(\u0026quot;Both threads have finished\u0026quot;); } } In this example, we create two threads t1 and t2 and start them. We then use the join() method to wait for both threads to finish before printing out a message indicating that both threads have finished.\nWhen t1.join() and t2.join() are called, the main thread will block and wait until both t1 and t2 have finished executing. Once both threads have completed, the main thread will continue executing and print out the final message.\n5. Resource Sharing in Threads\nIn Java, resource sharing can be achieved using the concept of synchronized monitors. A synchronized monitor is a mechanism that allows only one thread to access a shared resource at a time.\nTo use synchronized monitors in Java, you can use the synchronized keyword to define a block of code that needs to be executed by only one thread at a time. The synchronized keyword can be applied to a method or a block of code.\nHere\u0026rsquo;s an example of using synchronized monitors to share a resource in Java:\npublic class SharedResource { private int value; public synchronized void increment() { value++; } public synchronized int getValue() { return value; } } public class ResourceSharingExample { public static void main(String[] args) { SharedResource sharedResource = new SharedResource(); // create multiple threads to access the shared resource Thread t1 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) { sharedResource.increment(); } }); Thread t2 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) { sharedResource.increment(); } }); // start the threads t1.start(); t2.start(); // wait for the threads to finish try { t1.join(); t2.join(); } catch (InterruptedException e) { e.printStackTrace(); } // print the final value of the shared resource System.out.println(\u0026quot;Value: \u0026quot; + sharedResource.getValue()); } } In this example, the SharedResource class represents a shared resource that contains a single integer value. The increment() method and getValue() method are both marked as synchronized, which means that only one thread can access them at a time.\nThe ResourceSharingExample class creates two threads that access the shared resource using the increment() method. The threads run concurrently, but because of the synchronized monitors, only one thread can execute the increment() method at a time. The final value of the shared resource is printed at the end of the program, which should be 2000 in this case.\nWe also achieve some result using Object lock instead of synchronized monitors in Java.\npublic class SharedResource { private int value; private final Object lock = new Object(); public void increment() { synchronized (lock) { value++; } } public int getValue() { synchronized (lock) { return value; } } } public class ResourceSharingExample { public static void main(String[] args) { SharedResource sharedResource = new SharedResource(); // create multiple threads to access the shared resource Thread t1 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) { sharedResource.increment(); } }); Thread t2 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) { sharedResource.increment(); } }); // start the threads t1.start(); t2.start(); // wait for the threads to finish try { t1.join(); t2.join(); } catch (InterruptedException e) { e.printStackTrace(); } // print the final value of the shared resource System.out.println(\u0026quot;Value: \u0026quot; + sharedResource.getValue()); } } Using mutiple object locks threads can access the shared resources concurrently without interfering with each other.\npublic class SharedResource { private int value1; private int value2; private final Object lock1 = new Object(); private final Object lock2 = new Object(); public void incrementValue1() { synchronized (lock1) { value1++; } } public int getValue1() { synchronized (lock1) { return value1; } } public void incrementValue2() { synchronized (lock2) { value2++; } } public int getValue2() { synchronized (lock2) { return value2; } } } public class ResourceSharingExample { public static void main(String[] args) { SharedResource sharedResource = new SharedResource(); // create multiple threads to access the shared resource Thread t1 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) { sharedResource.incrementValue1(); } }); Thread t2 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) { sharedResource.incrementValue2(); } }); // start the threads t1.start(); t2.start(); // wait for the threads to finish try { t1.join(); t2.join(); } catch (InterruptedException e) { e.printStackTrace(); } // print the final values of the shared resources System.out.println(\u0026quot;Value1: \u0026quot; + sharedResource.getValue1()); System.out.println(\u0026quot;Value2: \u0026quot; + sharedResource.getValue2()); } } In this example, the SharedResource class contains two object locks, lock1 and lock2, and two methods for each value, incrementValue1(), getValue1(), incrementValue2(), and getValue2(). The incrementValue1() method and getValue1() method use lock1 to synchronize access to value1, while the incrementValue2() method and getValue2() method use lock2 to synchronize access to value2.\nThe ResourceSharingExample class creates two threads that access the shared resources using incrementValue1() and incrementValue2() methods. Because two different object locks are used to synchronize access to two different values, the threads can access the shared resources concurrently without interfering with each other. The final values of the shared resources are printed at the end of the program.\n6. Reentrant lock\nA ReentrantLock is a synchronization mechanism in Java that provides a way to protect shared resources from simultaneous access by multiple threads. It is called \u0026ldquo;reentrant\u0026rdquo; because a thread that already holds the lock can acquire it again without blocking, unlike traditional synchronization using the synchronized keyword.\nimport java.util.concurrent.locks.ReentrantLock; public class SharedResource { private int value; private ReentrantLock lock = new ReentrantLock(); public void incrementValue() { lock.lock(); try { value++; } finally { lock.unlock(); } } public int getValue() { lock.lock(); try { return value; } finally { lock.unlock(); } } } public class ResourceSharingExample { public static void main(String[] args) { SharedResource sharedResource = new SharedResource(); // create multiple threads to access the shared resource Thread t1 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) { sharedResource.incrementValue(); } }); Thread t2 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) { sharedResource.incrementValue(); } }); // start the threads t1.start(); t2.start(); // wait for the threads to finish try { t1.join(); t2.join(); } catch (InterruptedException e) { e.printStackTrace(); } // print the final value of the shared resource System.out.println(\u0026quot;Value: \u0026quot; + sharedResource.getValue()); } } In this example, the SharedResource class contains a single ReentrantLock and two methods for incrementing and retrieving the value variable. The lock object is used to synchronize access to the value variable.\nThe ResourceSharingExample class creates two threads that access the shared resource using the incrementValue() method. Because a ReentrantLock is used to synchronize access to the shared resource, the threads can access the shared resource concurrently without interfering with each other.\nReentrantLock is like a special key that allows threads to take turns accessing a shared resource. And if a thread already has the key, it can use it again without waiting in line. It provides query methods for testing lock\u0026rsquo;s internal state.\nExample of using ReentrantLock and tryLock() method in Java:\nimport java.util.concurrent.locks.ReentrantLock; public class Example { public static void main(String[] args) { ReentrantLock lock = new ReentrantLock(); // acquire the lock using tryLock() method boolean isLockAcquired = lock.tryLock(); if (isLockAcquired) { try { // perform critical section operations here System.out.println(\u0026quot;Lock acquired and critical section entered.\u0026quot;); } finally { // release the lock lock.unlock(); System.out.println(\u0026quot;Lock released.\u0026quot;); } } else { System.out.println(\u0026quot;Could not acquire lock. Another thread is holding the lock.\u0026quot;); } } } Example of using ReentrantReadWriteLock and tryLock() method in Java:\nimport java.util.HashMap; import java.util.Map; import java.util.concurrent.locks.ReadWriteLock; import java.util.concurrent.locks.ReentrantReadWriteLock; public class Example { private Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); private ReadWriteLock lock = new ReentrantReadWriteLock(); public void put(String key, String value) { lock.writeLock().lock(); // acquire write lock try { map.put(key, value); // perform write operation } finally { lock.writeLock().unlock(); // release write lock } } public String get(String key) { lock.readLock().lock(); // acquire read lock try { return map.get(key); // perform read operation } finally { lock.readLock().unlock(); // release read lock } } } In this example, we have a Map object that is accessed by multiple threads. To ensure thread safety and prevent race conditions, we use a ReadWriteLock to control access to the map.\nThe put() method acquires a write lock using the writeLock() method, performs a write operation on the map, and then releases the write lock using the unlock() method.\nThe get() method acquires a read lock using the readLock() method, performs a read operation on the map, and then releases the read lock using the unlock() method.\nWith this approach, multiple threads can simultaneously read from the map, but only one thread can write to the map at a time. This can significantly improve performance in scenarios where reads are much more frequent than writes.\n7. Volatile Keyword\nIn Java, the volatile keyword is used as a modifier to indicate that a variable\u0026rsquo;s value may be modified by multiple threads at the same time.\nWhen a variable is marked as volatile, the JVM ensures that any write to that variable is immediately visible to other threads that may access it. This means that changes made to the variable by one thread will be immediately reflected in the value seen by other threads. Without the volatile keyword, there is no guarantee that changes made by one thread will be immediately visible to another thread, which can lead to hard-to-detect bugs.\nThe volatile keyword can be used with any primitive type, as well as with references to objects. However, it\u0026rsquo;s important to note that using volatile does not provide atomicity, which means that if multiple threads try to modify the same variable at the same time, race conditions and inconsistencies can still occur.\nIn general, the volatile keyword should only be used when there is a specific need for multiple threads to access the same variable, and the programmer is sure that the volatile variable will be accessed in a safe and consistent way.\nHere\u0026rsquo;s an example to illustrate the use of volatile keyword in Java:\npublic class Counter { private volatile int count; public synchronized void increment() { count++; } public int getCount() { return count; } } In this example, we have a Counter class with a private volatile integer field called count. The increment() method is used to increment the value of count by one, and the getCount() method returns the current value of count.\nWithout the volatile keyword, there is no guarantee that changes made to count by one thread will be immediately visible to another thread. However, since count is marked as volatile, the JVM ensures that any write to count is immediately visible to other threads that may access it.\nConsider the following example usage of the Counter class by multiple threads:\npublic class Main { public static void main(String[] args) { Counter counter = new Counter(); Thread thread1 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 10000; i++) { counter.increment(); } }); Thread thread2 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 10000; i++) { counter.increment(); } }); thread1.start(); thread2.start(); try { thread1.join(); thread2.join(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026quot;Final count: \u0026quot; + counter.getCount()); } } In this example, we create two threads, thread1 and thread2, which both increment the Counter object\u0026rsquo;s count field 10,000 times. We then wait for both threads to complete using the join() method, and output the final value of count.\nWithout the volatile keyword on the count field in the Counter class, there is no guarantee that the final value of count will be 20,000. However, with count marked as volatile, we can be sure that changes made by one thread will be immediately visible to the other thread, and the final value of count will be 20,000.\n8. Deadlocks In Java, a deadlock occurs when two or more threads are blocked, waiting for each other to release the locks they hold. As a result, none of the threads can make progress and the program hangs.\nHere\u0026rsquo;s an example to illustrate how a deadlock can occur in Java:\npublic class DeadlockExample { private Object lock1 = new Object(); private Object lock2 = new Object(); public void method1() { synchronized (lock1) { System.out.println(\u0026quot;Acquired lock1 in method1\u0026quot;); try { Thread.sleep(1000); } catch (InterruptedException e) {} synchronized (lock2) { System.out.println(\u0026quot;Acquired lock2 in method1\u0026quot;); } } } public void method2() { synchronized (lock2) { System.out.println(\u0026quot;Acquired lock2 in method2\u0026quot;); try { Thread.sleep(1000); } catch (InterruptedException e) {} synchronized (lock1) { System.out.println(\u0026quot;Acquired lock1 in method2\u0026quot;); } } } public static void main(String[] args) { final DeadlockExample example = new DeadlockExample(); Thread thread1 = new Thread(new Runnable() { public void run() { example.method1(); } }); Thread thread2 = new Thread(new Runnable() { public void run() { example.method2(); } }); thread1.start(); thread2.start(); } } In this example, there are two methods, method1() and method2(), which each synchronize on a different lock. The main() method creates two threads that each call one of these methods.\nNow, suppose that thread1 acquires lock1 and then calls method2(), which tries to acquire lock2. At the same time, thread2 has already acquired lock2 and is trying to acquire lock1. Both threads are blocked waiting for the other thread to release its lock, causing a deadlock.\nDeadlock can occur in a concurrent system when the following conditions are met:\nMutual Exclusion: At least one resource is held in a mutually exclusive mode, meaning only one thread can use it at a time.\nHold and Wait: A thread is holding at least one resource and is waiting to acquire additional resources that are currently held by other threads.\nNo Preemption: Resources cannot be preempted or taken away from threads that are holding them. The only way to release a resource is for the thread to voluntarily release it.\nCircular Wait: A circular chain of threads exists, where each thread is waiting for a resource that is held by the next thread in the chain. In other words, there is a cycle in the resource allocation graph.\nTo avoid deadlocks, you can use some techniques like:\nAcquire locks in a fixed order.\nUse timeouts when acquiring locks to avoid indefinitely waiting for a lock.\nUse tryLock() instead of synchronized blocks to acquire locks in a non-blocking way.\nUse higher-level concurrency utilities like java.util.concurrent classes, which handle synchronization and - locking automatically.\n","content_html":"\u003cp\u003e\u003cstrong\u003e1. Thread creation\u003c/strong\u003e : In Java, you can create a thread by either extending the Thread class or implementing the Runnable interface. Here\u0026rsquo;s how you can do it:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExtending the Thread class:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class MyThread extends Thread {\n    public void run() {\n        // code to be executed in this thread\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can create an instance of the MyThread class and start the thread using the start() method:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eMyThread myThread = new MyThread();\nmyThread.start();\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eImplementing the Runnable interface:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class MyRunnable implements Runnable {\n    public void run() {\n        // code to be executed in this thread\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can create an instance of the MyRunnable class and pass it to a Thread object\u0026rsquo;s constructor:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eMyRunnable myRunnable = new MyRunnable();\nThread thread = new Thread(myRunnable);\nthread.start();\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn both cases, the run() method contains the code that will be executed when the thread is started. You should not call the run() method directly, but rather use the start() method to start the thread.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e2. Thread Termination\u003c/strong\u003e :\nFollowing are reasons to terminate a thread:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThreads in a computer consume various resources, such as memory, kernel resources, CPU cycles, and cache memory.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf a thread finished its work, but the application is still running we want to clean up the thread\u0026rsquo;s resources.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf a thread is misbehaving, we want to stop it.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe application will not stop as long as at least one thread is still running.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn Java, you can terminate a thread by calling the interrupt() method on the thread object. This method sets a flag on the thread to indicate that it should stop executing. However, it is up to the thread\u0026rsquo;s code to check for the interrupt flag and terminate gracefully.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class MyThread extends Thread {\n    @Override\n    public void run() {\n        while (!Thread.currentThread().isInterrupted()) {\n            // do some work\n        }\n        System.out.println(\u0026quot;Thread is terminating.\u0026quot;);\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        MyThread thread = new MyThread();\n        thread.start();\n\n        // Interrupt the thread\n        thread.interrupt();\n    }\n}\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, the MyThread class extends the Thread class and overrides the run() method to do some work in a loop. Inside the loop, the thread checks if it has been interrupted using the isInterrupted() method.\u003c/p\u003e\n\u003cp\u003eIn the Main class, we create an instance of MyThread and start it. When the interrupt() method is called, the isInterrupted() method in the MyThread class will return true, causing the thread to exit the loop and terminate gracefully.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e3. Daemon Threads\u003c/strong\u003e :\nIn Java, a daemon thread is a type of thread that runs in the background and does not prevent the Java Virtual Machine (JVM) from exiting when the program finishes execution.\u003c/p\u003e\n\u003cp\u003eDaemon threads are typically used for tasks that need to run continuously in the background, such as garbage collection or other system-level tasks. They are also commonly used in server applications to perform tasks like cleaning up old connections or handling periodic maintenance tasks.\u003c/p\u003e\n\u003cp\u003eTo create a daemon thread in Java, you can use the setDaemon() method on a Thread object. For example, the following code creates a new thread and sets it as a daemon thread:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eThread myThread = new Thread(new Runnable() {\n    public void run() {\n        // Do some background task here\n    }\n});\nmyThread.setDaemon(true);\nmyThread.start();\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce a thread is set as a daemon thread, you cannot change it back to a non-daemon thread.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e4. Joining Threads\u003c/strong\u003e :\u003c/p\u003e\n\u003cp\u003eJoining threads in Java is done using the join() method, which allows one thread to wait for another thread to complete before continuing. Here\u0026rsquo;s a simple example of how to use the join() method to join two threads:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class JoinExample {\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread t1 = new Thread(() -\u0026gt; {\n            System.out.println(\u0026quot;Thread 1 is running\u0026quot;);\n            try {\n                Thread.sleep(2000); // simulate some work being done\n            } catch (InterruptedException e) {\n                System.out.println(\u0026quot;Thread 1 was interrupted\u0026quot;);\n            }\n            System.out.println(\u0026quot;Thread 1 is finished\u0026quot;);\n        });\n\n        Thread t2 = new Thread(() -\u0026gt; {\n            System.out.println(\u0026quot;Thread 2 is running\u0026quot;);\n            try {\n                Thread.sleep(1000); // simulate some work being done\n            } catch (InterruptedException e) {\n                System.out.println(\u0026quot;Thread 2 was interrupted\u0026quot;);\n            }\n            System.out.println(\u0026quot;Thread 2 is finished\u0026quot;);\n        });\n\n        t1.start();\n        t2.start();\n\n        // wait for both threads to finish\n        t1.join();\n        t2.join();\n\n        System.out.println(\u0026quot;Both threads have finished\u0026quot;);\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, we create two threads t1 and t2 and start them. We then use the join() method to wait for both threads to finish before printing out a message indicating that both threads have finished.\u003c/p\u003e\n\u003cp\u003eWhen t1.join() and t2.join() are called, the main thread will block and wait until both t1 and t2 have finished executing. Once both threads have completed, the main thread will continue executing and print out the final message.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e5. Resource Sharing in Threads\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIn Java, resource sharing can be achieved using the concept of synchronized monitors. A synchronized monitor is a mechanism that allows only one thread to access a shared resource at a time.\u003c/p\u003e\n\u003cp\u003eTo use synchronized monitors in Java, you can use the synchronized keyword to define a block of code that needs to be executed by only one thread at a time. The synchronized keyword can be applied to a method or a block of code.\u003c/p\u003e\n\u003cp\u003eHere\u0026rsquo;s an example of using synchronized monitors to share a resource in Java:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class SharedResource {\n    private int value;\n\n    public synchronized void increment() {\n        value++;\n    }\n\n    public synchronized int getValue() {\n        return value;\n    }\n}\n\npublic class ResourceSharingExample {\n    public static void main(String[] args) {\n        SharedResource sharedResource = new SharedResource();\n\n        // create multiple threads to access the shared resource\n        Thread t1 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 1000; i++) {\n                sharedResource.increment();\n            }\n        });\n\n        Thread t2 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 1000; i++) {\n                sharedResource.increment();\n            }\n        });\n\n        // start the threads\n        t1.start();\n        t2.start();\n\n        // wait for the threads to finish\n        try {\n            t1.join();\n            t2.join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        // print the final value of the shared resource\n        System.out.println(\u0026quot;Value: \u0026quot; + sharedResource.getValue());\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, the SharedResource class represents a shared resource that contains a single integer value. The increment() method and getValue() method are both marked as synchronized, which means that only one thread can access them at a time.\u003c/p\u003e\n\u003cp\u003eThe ResourceSharingExample class creates two threads that access the shared resource using the increment() method. The threads run concurrently, but because of the synchronized monitors, only one thread can execute the increment() method at a time. The final value of the shared resource is printed at the end of the program, which should be 2000 in this case.\u003c/p\u003e\n\u003cp\u003eWe also achieve some result using Object lock instead of synchronized monitors in Java.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class SharedResource {\n    private int value;\n    private final Object lock = new Object();\n\n    public void increment() {\n        synchronized (lock) {\n            value++;\n        }\n    }\n\n    public int getValue() {\n        synchronized (lock) {\n            return value;\n        }\n    }\n}\n\npublic class ResourceSharingExample {\n    public static void main(String[] args) {\n        SharedResource sharedResource = new SharedResource();\n\n        // create multiple threads to access the shared resource\n        Thread t1 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 1000; i++) {\n                sharedResource.increment();\n            }\n        });\n\n        Thread t2 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 1000; i++) {\n                sharedResource.increment();\n            }\n        });\n\n        // start the threads\n        t1.start();\n        t2.start();\n\n        // wait for the threads to finish\n        try {\n            t1.join();\n            t2.join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        // print the final value of the shared resource\n        System.out.println(\u0026quot;Value: \u0026quot; + sharedResource.getValue());\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUsing mutiple object locks threads can access the shared resources concurrently without interfering with each other.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class SharedResource {\n    private int value1;\n    private int value2;\n    private final Object lock1 = new Object();\n    private final Object lock2 = new Object();\n\n    public void incrementValue1() {\n        synchronized (lock1) {\n            value1++;\n        }\n    }\n\n    public int getValue1() {\n        synchronized (lock1) {\n            return value1;\n        }\n    }\n\n    public void incrementValue2() {\n        synchronized (lock2) {\n            value2++;\n        }\n    }\n\n    public int getValue2() {\n        synchronized (lock2) {\n            return value2;\n        }\n    }\n}\n\npublic class ResourceSharingExample {\n    public static void main(String[] args) {\n        SharedResource sharedResource = new SharedResource();\n\n        // create multiple threads to access the shared resource\n        Thread t1 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 1000; i++) {\n                sharedResource.incrementValue1();\n            }\n        });\n\n        Thread t2 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 1000; i++) {\n                sharedResource.incrementValue2();\n            }\n        });\n\n        // start the threads\n        t1.start();\n        t2.start();\n\n        // wait for the threads to finish\n        try {\n            t1.join();\n            t2.join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        // print the final values of the shared resources\n        System.out.println(\u0026quot;Value1: \u0026quot; + sharedResource.getValue1());\n        System.out.println(\u0026quot;Value2: \u0026quot; + sharedResource.getValue2());\n    }\n}\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, the SharedResource class contains two object locks, lock1 and lock2, and two methods for each value, incrementValue1(), getValue1(), incrementValue2(), and getValue2(). The incrementValue1() method and getValue1() method use lock1 to synchronize access to value1, while the incrementValue2() method and getValue2() method use lock2 to synchronize access to value2.\u003c/p\u003e\n\u003cp\u003eThe ResourceSharingExample class creates two threads that access the shared resources using incrementValue1() and incrementValue2() methods. Because two different object locks are used to synchronize access to two different values, the \u003cstrong\u003ethreads can access the shared resources concurrently without interfering with each other\u003c/strong\u003e. The final values of the shared resources are printed at the end of the program.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e6. Reentrant lock\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eA ReentrantLock is a synchronization mechanism in Java that provides a way to protect shared resources from simultaneous access by multiple threads. It is called \u0026ldquo;reentrant\u0026rdquo; because a thread that already holds the lock can acquire it again without blocking, unlike traditional synchronization using the synchronized keyword.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eimport java.util.concurrent.locks.ReentrantLock;\n\npublic class SharedResource {\n    private int value;\n    private ReentrantLock lock = new ReentrantLock();\n\n    public void incrementValue() {\n        lock.lock();\n        try {\n            value++;\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public int getValue() {\n        lock.lock();\n        try {\n            return value;\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n\npublic class ResourceSharingExample {\n    public static void main(String[] args) {\n        SharedResource sharedResource = new SharedResource();\n\n        // create multiple threads to access the shared resource\n        Thread t1 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 1000; i++) {\n                sharedResource.incrementValue();\n            }\n        });\n\n        Thread t2 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 1000; i++) {\n                sharedResource.incrementValue();\n            }\n        });\n\n        // start the threads\n        t1.start();\n        t2.start();\n\n        // wait for the threads to finish\n        try {\n            t1.join();\n            t2.join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        // print the final value of the shared resource\n        System.out.println(\u0026quot;Value: \u0026quot; + sharedResource.getValue());\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, the SharedResource class contains a single ReentrantLock and two methods for incrementing and retrieving the value variable. The lock object is used to synchronize access to the value variable.\u003c/p\u003e\n\u003cp\u003eThe ResourceSharingExample class creates two threads that access the shared resource using the incrementValue() method. Because a ReentrantLock is used to synchronize access to the shared resource, the threads can access the shared resource concurrently without interfering with each other.\u003c/p\u003e\n\u003cp\u003eReentrantLock is like a special key that allows threads to take turns accessing a shared resource. And if a thread already has the key, it can use it again without waiting in line. It provides query methods for testing lock\u0026rsquo;s internal state.\u003c/p\u003e\n\u003cp\u003eExample of using ReentrantLock and tryLock() method in Java:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eimport java.util.concurrent.locks.ReentrantLock;\n\npublic class Example {\n    public static void main(String[] args) {\n        ReentrantLock lock = new ReentrantLock();\n\n        // acquire the lock using tryLock() method\n        boolean isLockAcquired = lock.tryLock();\n\n        if (isLockAcquired) {\n            try {\n                // perform critical section operations here\n                System.out.println(\u0026quot;Lock acquired and critical section entered.\u0026quot;);\n            } finally {\n                // release the lock\n                lock.unlock();\n                System.out.println(\u0026quot;Lock released.\u0026quot;);\n            }\n        } else {\n            System.out.println(\u0026quot;Could not acquire lock. Another thread is holding the lock.\u0026quot;);\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eExample of using ReentrantReadWriteLock and tryLock() method in Java:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.locks.ReadWriteLock;\nimport java.util.concurrent.locks.ReentrantReadWriteLock;\n\npublic class Example {\n    private Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;();\n    private ReadWriteLock lock = new ReentrantReadWriteLock();\n\n    public void put(String key, String value) {\n        lock.writeLock().lock(); // acquire write lock\n        try {\n            map.put(key, value); // perform write operation\n        } finally {\n            lock.writeLock().unlock(); // release write lock\n        }\n    }\n\n    public String get(String key) {\n        lock.readLock().lock(); // acquire read lock\n        try {\n            return map.get(key); // perform read operation\n        } finally {\n            lock.readLock().unlock(); // release read lock\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, we have a Map object that is accessed by multiple threads. To ensure thread safety and prevent race conditions, we use a ReadWriteLock to control access to the map.\u003c/p\u003e\n\u003cp\u003eThe put() method acquires a write lock using the writeLock() method, performs a write operation on the map, and then releases the write lock using the unlock() method.\u003c/p\u003e\n\u003cp\u003eThe get() method acquires a read lock using the readLock() method, performs a read operation on the map, and then releases the read lock using the unlock() method.\u003c/p\u003e\n\u003cp\u003eWith this approach, multiple threads can simultaneously read from the map, but only one thread can write to the map at a time. This can significantly improve performance in scenarios where reads are much more frequent than writes.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e7. Volatile Keyword\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIn Java, the volatile keyword is used as a modifier to indicate that a variable\u0026rsquo;s value may be modified by multiple threads at the same time.\u003c/p\u003e\n\u003cp\u003eWhen a variable is marked as volatile, the JVM ensures that any write to that variable is immediately visible to other threads that may access it. This means that changes made to the variable by one thread will be immediately reflected in the value seen by other threads. Without the volatile keyword, there is no guarantee that changes made by one thread will be immediately visible to another thread, which can lead to hard-to-detect bugs.\u003c/p\u003e\n\u003cp\u003eThe volatile keyword can be used with any primitive type, as well as with references to objects. However, it\u0026rsquo;s important to note that using volatile does not provide atomicity, which means that if multiple threads try to modify the same variable at the same time, race conditions and inconsistencies can still occur.\u003c/p\u003e\n\u003cp\u003eIn general, the volatile keyword should only be used when there is a specific need for multiple threads to access the same variable, and the programmer is sure that the volatile variable will be accessed in a safe and consistent way.\u003c/p\u003e\n\u003cp\u003eHere\u0026rsquo;s an example to illustrate the use of volatile keyword in Java:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class Counter {\n    private volatile int count;\n\n    public synchronized void increment() {\n        count++;\n    }\n\n    public int getCount() {\n        return count;\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, we have a Counter class with a private volatile integer field called count. The increment() method is used to increment the value of count by one, and the getCount() method returns the current value of count.\u003c/p\u003e\n\u003cp\u003eWithout the volatile keyword, there is no guarantee that changes made to count by one thread will be immediately visible to another thread. However, since count is marked as volatile, the JVM ensures that any write to count is immediately visible to other threads that may access it.\u003c/p\u003e\n\u003cp\u003eConsider the following example usage of the Counter class by multiple threads:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class Main {\n    public static void main(String[] args) {\n        Counter counter = new Counter();\n\n        Thread thread1 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 10000; i++) {\n                counter.increment();\n            }\n        });\n\n        Thread thread2 = new Thread(() -\u0026gt; {\n            for (int i = 0; i \u0026lt; 10000; i++) {\n                counter.increment();\n            }\n        });\n\n        thread1.start();\n        thread2.start();\n\n        try {\n            thread1.join();\n            thread2.join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        System.out.println(\u0026quot;Final count: \u0026quot; + counter.getCount());\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, we create two threads, thread1 and thread2, which both increment the Counter object\u0026rsquo;s count field 10,000 times. We then wait for both threads to complete using the join() method, and output the final value of count.\u003c/p\u003e\n\u003cp\u003eWithout the volatile keyword on the count field in the Counter class, there is no guarantee that the final value of count will be 20,000. However, with count marked as volatile, we can be sure that changes made by one thread will be immediately visible to the other thread, and the final value of count will be 20,000.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e8. Deadlocks\u003c/strong\u003e\nIn Java, a deadlock occurs when two or more threads are blocked, waiting for each other to release the locks they hold. As a result, none of the threads can make progress and the program hangs.\u003c/p\u003e\n\u003cp\u003eHere\u0026rsquo;s an example to illustrate how a deadlock can occur in Java:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003epublic class DeadlockExample {\n    private Object lock1 = new Object();\n    private Object lock2 = new Object();\n\n    public void method1() {\n        synchronized (lock1) {\n            System.out.println(\u0026quot;Acquired lock1 in method1\u0026quot;);\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {}\n            synchronized (lock2) {\n                System.out.println(\u0026quot;Acquired lock2 in method1\u0026quot;);\n            }\n        }\n    }\n\n    public void method2() {\n        synchronized (lock2) {\n            System.out.println(\u0026quot;Acquired lock2 in method2\u0026quot;);\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {}\n            synchronized (lock1) {\n                System.out.println(\u0026quot;Acquired lock1 in method2\u0026quot;);\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        final DeadlockExample example = new DeadlockExample();\n        Thread thread1 = new Thread(new Runnable() {\n            public void run() {\n                example.method1();\n            }\n        });\n        Thread thread2 = new Thread(new Runnable() {\n            public void run() {\n                example.method2();\n            }\n        });\n        thread1.start();\n        thread2.start();\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, there are two methods, method1() and method2(), which each synchronize on a different lock. The main() method creates two threads that each call one of these methods.\u003c/p\u003e\n\u003cp\u003eNow, suppose that thread1 acquires lock1 and then calls method2(), which tries to acquire lock2. At the same time, thread2 has already acquired lock2 and is trying to acquire lock1. Both threads are blocked waiting for the other thread to release its lock, causing a deadlock.\u003c/p\u003e\n\u003cp\u003eDeadlock can occur in a concurrent system when the following conditions are met:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eMutual Exclusion: At least one resource is held in a mutually exclusive mode, meaning only one thread can use it at a time.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHold and Wait: A thread is holding at least one resource and is waiting to acquire additional resources that are currently held by other threads.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNo Preemption: Resources cannot be preempted or taken away from threads that are holding them. The only way to release a resource is for the thread to voluntarily release it.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCircular Wait: A circular chain of threads exists, where each thread is waiting for a resource that is held by the next thread in the chain. In other words, there is a cycle in the resource allocation graph.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTo avoid deadlocks, you can use some techniques like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eAcquire locks in a fixed order.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUse timeouts when acquiring locks to avoid indefinitely waiting for a lock.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUse tryLock() instead of synchronized blocks to acquire locks in a non-blocking way.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUse higher-level concurrency utilities like java.util.concurrent classes, which handle synchronization and - locking automatically.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","url":"https://karthikselvam.com/posts/2023/01/23/threads/","image":"https://karthikselvam.com/photos/<no value>","banner_image":"https://karthikselvam.com/photos/<no value>","date_published":"23016-23-09T10:2323:00+00:00","date_modified":"23016-23-09T10:2323:00+00:00","author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"}},{"id":"f7d5285750b0c221397309ad910af98f154422a2","title":"Handling Transactions in Microservices","summary":"2023","content_text":"Handling transactions involving more than one microservice can be challenging since each microservice typically has its own data store and transaction management. However, there are several best practices that can help to ensure consistency and reliability across microservices:\nThe Saga pattern: This involves breaking the transaction into multiple smaller transactions, each of which is handled by a separate microservice. If a transaction fails, the other services can be rolled back, ensuring that the system remains consistent. Let\u0026rsquo;s say you have a system where a user can place an order that involves multiple microservices. The order might involve checking inventory levels, processing payments, and shipping products. You can use the Saga pattern to handle this transaction by breaking it down into smaller transactions, each handled by a separate microservice. If one of the transactions fails, the other transactions can be rolled back, ensuring that the system remains consistent. For example, the payment service fails to process a payment. The shipping service can be notified to cancel the shipment, and the inventory service can be notified to restock the item. This ensures that the system remains consistent even though one of the transactions failed.\nDistributed transaction coordinator: A distributed transaction coordinator can help to manage transactions across multiple microservices. The coordinator can ensure that all transactions are either committed or rolled back as a single unit, ensuring consistency across the system.For example, you could use a tool like Apache Kafka to implement a distributed transaction coordinator. When a user places an order, the order microservice can publish a message to a Kafka topic. Each microservice that needs to handle the transaction can subscribe to the topic and perform its own transaction. If one of the microservices fails, the coordinator can ensure that all transactions are either committed or rolled back as a single unit, ensuring consistency across the system.\nCompensating transactions: A compensating transaction is a transaction that undoes the effects of a previous transaction. This can be used to handle failures in the system by rolling back the changes made by previous transactions and restoring the system to its previous state.For example, Let\u0026rsquo;s say you have a system where a user can transfer money between accounts. This transaction involves two microservices: one to debit the account and another to credit the account. If the credit service fails, you can use a compensating transaction to handle the failure. The debit service can be notified to reverse the debit transaction, ensuring that the system remains consistent.\nEvent-driven architectures: In an event-driven architecture, each microservice publishes events when it completes a transaction. Other microservices can subscribe to these events and use them to trigger their own transactions. This can help to ensure consistency across the system and reduce the risk of failures.For example, Let\u0026rsquo;s say you have a system where a user can place an order that involves multiple microservices. Each microservice can publish an event when it completes a transaction. For example, the inventory service can publish an event when it updates the inventory level, and the shipping service can publish an event when it ships the product. Other microservices can subscribe to these events and use them to trigger their own transactions. This can help to ensure consistency across the system and reduce the risk of failures.\nIdempotency: Idempotency is the property of a system where performing the same operation multiple times has the same result as performing it once. By designing microservices to be idempotent, you can reduce the risk of failures and ensure consistency across the system.For example, Let\u0026rsquo;s say you have a system where a user can update their profile information. To ensure idempotency, you can design the microservice to only update the profile if the request includes a unique identifier, such as a UUID. If the same request is made multiple times, the microservice will recognize the duplicate request and return the same result as the original request. This ensures that the system remains consistent even if the same request is made multiple times.\n","content_html":"\u003cp\u003eHandling transactions involving more than one microservice can be challenging since each microservice typically has its own data store and transaction management. However, there are several best practices that can help to ensure consistency and reliability across microservices:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eThe Saga pattern\u003c/strong\u003e: This involves breaking the transaction into multiple smaller transactions, each of which is handled by a separate microservice. If a transaction fails, the other services can be rolled back, ensuring that the system remains consistent. Let\u0026rsquo;s say you have a system where a user can place an order that involves multiple microservices. The order might involve checking inventory levels, processing payments, and shipping products. You can use the Saga pattern to handle this transaction by breaking it down into smaller transactions, each handled by a separate microservice. If one of the transactions fails, the other transactions can be rolled back, ensuring that the system remains consistent. For example, the payment service fails to process a payment. The shipping service can be notified to cancel the shipment, and the inventory service can be notified to restock the item. This ensures that the system remains consistent even though one of the transactions failed.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eDistributed transaction coordinator\u003c/strong\u003e: A distributed transaction coordinator can help to manage transactions across multiple microservices. The coordinator can ensure that all transactions are either committed or rolled back as a single unit, ensuring consistency across the system.For example, you could use a tool like Apache Kafka to implement a distributed transaction coordinator. When a user places an order, the order microservice can publish a message to a Kafka topic. Each microservice that needs to handle the transaction can subscribe to the topic and perform its own transaction. If one of the microservices fails, the coordinator can ensure that all transactions are either committed or rolled back as a single unit, ensuring consistency across the system.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eCompensating transactions\u003c/strong\u003e: A compensating transaction is a transaction that undoes the effects of a previous transaction. This can be used to handle failures in the system by rolling back the changes made by previous transactions and restoring the system to its previous state.For example, Let\u0026rsquo;s say you have a system where a user can transfer money between accounts. This transaction involves two microservices: one to debit the account and another to credit the account. If the credit service fails, you can use a compensating transaction to handle the failure. The debit service can be notified to reverse the debit transaction, ensuring that the system remains consistent.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eEvent-driven architectures\u003c/strong\u003e: In an event-driven architecture, each microservice publishes events when it completes a transaction. Other microservices can subscribe to these events and use them to trigger their own transactions. This can help to ensure consistency across the system and reduce the risk of failures.For example, Let\u0026rsquo;s say you have a system where a user can place an order that involves multiple microservices. Each microservice can publish an event when it completes a transaction. For example, the inventory service can publish an event when it updates the inventory level, and the shipping service can publish an event when it ships the product. Other microservices can subscribe to these events and use them to trigger their own transactions. This can help to ensure consistency across the system and reduce the risk of failures.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eIdempotency\u003c/strong\u003e: Idempotency is the property of a system where performing the same operation multiple times has the same result as performing it once. By designing microservices to be idempotent, you can reduce the risk of failures and ensure consistency across the system.For example, Let\u0026rsquo;s say you have a system where a user can update their profile information. To ensure idempotency, you can design the microservice to only update the profile if the request includes a unique identifier, such as a UUID. If the same request is made multiple times, the microservice will recognize the duplicate request and return the same result as the original request. This ensures that the system remains consistent even if the same request is made multiple times.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n","url":"https://karthikselvam.com/posts/2023/01/23/transactions/","image":"https://karthikselvam.com/photos/<no value>","banner_image":"https://karthikselvam.com/photos/<no value>","date_published":"23016-23-09T10:2323:00+00:00","date_modified":"23016-23-09T10:2323:00+00:00","author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"}},{"id":"b90cc9bfd23567a2ff5ba1f00e7c63ca6da8755e","title":"Arrays","summary":"2023","content_text":"1. Tell me about a time when you went above and beyond to meet customer needs. Situation: In my previous role as a Senior Software Development Engineer at [Company Name], we had a critical customer who relied heavily on one of our core services for their day-to-day operations. The service was generally reliable, but we noticed an increase in latency during peak hours, which started to affect the customer’s business. They were experiencing delays that disrupted their workflow, leading to frustration and potential loss of business for them.\nTask: As the senior engineer responsible for the service, I was tasked with investigating the root cause of the latency and finding a solution. The challenge was that this issue was intermittent and had not surfaced in our regular testing or monitoring processes. Additionally, the customer had an important launch event in two weeks, and they needed this issue resolved before then.\nAction: I decided to go beyond the typical debugging process and took the following steps:\nDeep Dive into Logs: I led a detailed analysis of logs and metrics from both our production and pre-production environments to identify patterns during peak times. I involved the DevOps team to help simulate the exact production load in a controlled environment.\nCustomer Collaboration: I personally reached out to the customer’s technical team to understand the specific scenarios where they were facing issues. This allowed me to replicate their exact usage patterns and identify bottlenecks that weren’t evident in generic load testing.\nOptimizing the Code: Upon identifying the bottleneck, I worked on optimizing the service\u0026rsquo;s code, specifically focusing on the database queries and caching mechanisms that were causing the delays. I also refactored parts of the code to make the service more resilient under heavy load.\nProactive Communication: Throughout this process, I kept the customer informed about our progress, ensuring that they felt supported and knew we were prioritizing their needs.\nTesting and Deployment: Once the optimizations were implemented, I coordinated with the QA team to conduct rigorous testing. I also worked with the DevOps team to deploy the changes in a phased manner, closely monitoring the service during the deployment to ensure there were no regressions.\nResult: The optimization efforts reduced the service\u0026rsquo;s latency by 60% during peak hours, which significantly improved the customer’s experience. The issue was resolved well before their launch event, and they were able to proceed without any disruptions. The customer was highly appreciative of the proactive approach and the level of detail we went into to solve their problem. This not only strengthened our relationship with them but also led to a long-term partnership and additional business opportunities.\nReflection: This experience reinforced the importance of being customer-obsessed, especially in a senior role. Going beyond the expected duties, engaging directly with the customer, and ensuring that their needs are met, even under tight deadlines, is crucial in building trust and delivering exceptional service.\n2. Can you provide an example of a time when you received negative customer feedback? What did you do to address it? Situation: In my previous role as a Senior Software Development Engineer at [Company Name], we launched a new version of our platform with several major updates and features. However, shortly after the release, we started receiving negative feedback from a key customer segment. They reported that the new user interface was confusing, and some of the features they relied on were either harder to access or didn’t work as expected.\nTask: As the senior engineer responsible for this project, my task was to address the feedback promptly. This involved understanding the root cause of the issues, devising a plan to resolve them, and restoring customer satisfaction.\nAction: To tackle this, I took the following steps:\nEngage Directly with Customers: I initiated direct communication with the affected customers to gather detailed feedback. I set up calls and meetings with key users to understand their specific pain points and how the changes impacted their workflow. This allowed me to get a clearer picture of the issues beyond what was reported in generic feedback channels.\nAnalyze the Feedback: I worked closely with the UX team to analyze the feedback and identify common patterns. We discovered that the navigation changes we made, though intended to streamline the interface, had unintentionally made it harder for some users to complete their tasks efficiently. Additionally, there were a few bugs in the new features that had slipped through our testing process.\nImplement Rapid Improvements: Based on the feedback, I prioritized quick wins that could immediately improve the user experience. We rolled out a patch that fixed the bugs and made some immediate adjustments to the navigation flow based on customer input. I also proposed and led a short-term project to create customizable interface options, allowing users to revert to a layout closer to the previous version if they preferred it.\nProactive Communication: Throughout this process, I maintained open lines of communication with the affected customers, providing regular updates on our progress and the changes we were making. I also took the opportunity to thank them for their feedback and assured them that we were committed to addressing their concerns.\nPost-Release Follow-Up: After the changes were implemented, I followed up with the customers to gather additional feedback and ensure the modifications addressed their issues. I also monitored the platform for further feedback to ensure the improvements were well-received.\nResult: The quick response and the adjustments we made led to a significant reduction in customer complaints, and the feedback shifted from negative to positive. The customizable interface option was particularly well-received, as it gave users more control over their experience. Our relationship with the customers improved, and they appreciated our responsiveness and willingness to adapt based on their needs.\nReflection: This experience reinforced the importance of actively listening to customer feedback and being agile in responding to it. By engaging directly with customers and being transparent about the steps we were taking, we were able to turn a negative situation into a positive one, ultimately enhancing the customer experience and strengthening our product.\n3. Tell me about a time when you had to deliver a product or feature under a tight deadline. How did you ensure it met customer expectations?? Situation: At my previous company, we had a client who requested a new feature for their application just weeks before their product launch. The feature was crucial for their marketing campaign, and they needed it delivered within an extremely tight deadline of two weeks.\nTask: As the lead developer, my task was to ensure that we delivered a fully functional, high-quality feature on time, without compromising our existing development schedule.\nAction: I started by breaking down the feature requirements into manageable tasks and prioritized them based on the client’s most critical needs. I then assembled a small team of developers and designers, ensuring everyone was clear on their responsibilities and the importance of meeting the deadline.\nTo maximize efficiency, I implemented daily stand-up meetings to track progress, identify any roadblocks early, and make quick decisions. I also set up a continuous integration pipeline to automate testing and deployment, so that we could catch and fix bugs as early as possible.\nThroughout the development process, I maintained close communication with the client to keep them updated on our progress and to manage their expectations. This also allowed us to get quick feedback on the feature’s implementation, ensuring we were aligned with their vision.\nResult: We successfully delivered the feature on time, and it met the client’s expectations in terms of functionality and quality. The client was impressed with our ability to meet such a tight deadline without compromising on the end product. This experience not only strengthened our relationship with the client but also demonstrated our team’s ability to work efficiently under pressure.\n4. Tell about a time you disagreed with your teamamt? Situation: In one of my previous projects, we were tasked with breaking down a monolithic application into microservices. The goal was to improve scalability and maintainability.\nTask: My role was to design the microservices architecture and ensure a smooth transition from the monolithic system. However, a teammate and I had a fundamental disagreement about how to approach this.\nAction: My teammate advocated for a \u0026ldquo;big bang\u0026rdquo; approach, where we would decompose the entire application at once and deploy all microservices simultaneously. They believed this would be more efficient and faster. I, on the other hand, favored an incremental approach. I suggested breaking down the application one component at a time, deploying each microservice individually, and ensuring that each one worked correctly before moving on to the next. I felt this would minimize risk and make it easier to identify and fix issues.\nTo resolve the disagreement, we decided to: Discuss Concerns: We sat down and outlined the pros and cons of both approaches. I highlighted the potential risks of a \u0026ldquo;big bang\u0026rdquo; deployment, such as the difficulty in debugging and the high impact of potential failures. Run Experiments: We agreed to conduct a proof-of-concept by splitting one part of the monolith into a microservice and deploying it. This would give us insights into the complexity and potential issues we might face. Consult with Stakeholders: We brought in our tech lead and a few other senior engineers to get their perspectives and advice. They supported the idea of an incremental approach given the complexity of our system.\nResult: The proof-of-concept was successful and demonstrated the benefits of an incremental approach. It allowed us to catch and resolve issues early, and it provided the team with valuable learning experiences. As a result, we adopted the incremental approach for the rest of the project.\nIn the end, the project was a success. The incremental approach proved to be effective in managing risks and ensuring a smooth transition to microservices. This experience reinforced the importance of open communication, experimentation, and involving stakeholders in decision-making processes.\n","content_html":"\u003cp\u003e\u003cstrong\u003e1. Tell me about a time when you went above and beyond to meet customer needs.\u003c/strong\u003e\nSituation: In my previous role as a Senior Software Development Engineer at [Company Name], we had a critical customer who relied heavily on one of our core services for their day-to-day operations. The service was generally reliable, but we noticed an increase in latency during peak hours, which started to affect the customer’s business. They were experiencing delays that disrupted their workflow, leading to frustration and potential loss of business for them.\u003c/p\u003e\n\u003cp\u003eTask: As the senior engineer responsible for the service, I was tasked with investigating the root cause of the latency and finding a solution. The challenge was that this issue was intermittent and had not surfaced in our regular testing or monitoring processes. Additionally, the customer had an important launch event in two weeks, and they needed this issue resolved before then.\u003c/p\u003e\n\u003cp\u003eAction:\nI decided to go beyond the typical debugging process and took the following steps:\u003c/p\u003e\n\u003cp\u003eDeep Dive into Logs: I led a detailed analysis of logs and metrics from both our production and pre-production environments to identify patterns during peak times. I involved the DevOps team to help simulate the exact production load in a controlled environment.\u003c/p\u003e\n\u003cp\u003eCustomer Collaboration: I personally reached out to the customer’s technical team to understand the specific scenarios where they were facing issues. This allowed me to replicate their exact usage patterns and identify bottlenecks that weren’t evident in generic load testing.\u003c/p\u003e\n\u003cp\u003eOptimizing the Code: Upon identifying the bottleneck, I worked on optimizing the service\u0026rsquo;s code, specifically focusing on the database queries and caching mechanisms that were causing the delays. I also refactored parts of the code to make the service more resilient under heavy load.\u003c/p\u003e\n\u003cp\u003eProactive Communication: Throughout this process, I kept the customer informed about our progress, ensuring that they felt supported and knew we were prioritizing their needs.\u003c/p\u003e\n\u003cp\u003eTesting and Deployment: Once the optimizations were implemented, I coordinated with the QA team to conduct rigorous testing. I also worked with the DevOps team to deploy the changes in a phased manner, closely monitoring the service during the deployment to ensure there were no regressions.\u003c/p\u003e\n\u003cp\u003eResult:\nThe optimization efforts reduced the service\u0026rsquo;s latency by 60% during peak hours, which significantly improved the customer’s experience. The issue was resolved well before their launch event, and they were able to proceed without any disruptions. The customer was highly appreciative of the proactive approach and the level of detail we went into to solve their problem. This not only strengthened our relationship with them but also led to a long-term partnership and additional business opportunities.\u003c/p\u003e\n\u003cp\u003eReflection:\nThis experience reinforced the importance of being customer-obsessed, especially in a senior role. Going beyond the expected duties, engaging directly with the customer, and ensuring that their needs are met, even under tight deadlines, is crucial in building trust and delivering exceptional service.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. Can you provide an example of a time when you received negative customer feedback? What did you do to address it?\u003c/strong\u003e\nSituation:\nIn my previous role as a Senior Software Development Engineer at [Company Name], we launched a new version of our platform with several major updates and features. However, shortly after the release, we started receiving negative feedback from a key customer segment. They reported that the new user interface was confusing, and some of the features they relied on were either harder to access or didn’t work as expected.\u003c/p\u003e\n\u003cp\u003eTask:\nAs the senior engineer responsible for this project, my task was to address the feedback promptly. This involved understanding the root cause of the issues, devising a plan to resolve them, and restoring customer satisfaction.\u003c/p\u003e\n\u003cp\u003eAction:\nTo tackle this, I took the following steps:\u003c/p\u003e\n\u003cp\u003eEngage Directly with Customers:\nI initiated direct communication with the affected customers to gather detailed feedback. I set up calls and meetings with key users to understand their specific pain points and how the changes impacted their workflow. This allowed me to get a clearer picture of the issues beyond what was reported in generic feedback channels.\u003c/p\u003e\n\u003cp\u003eAnalyze the Feedback:\nI worked closely with the UX team to analyze the feedback and identify common patterns. We discovered that the navigation changes we made, though intended to streamline the interface, had unintentionally made it harder for some users to complete their tasks efficiently. Additionally, there were a few bugs in the new features that had slipped through our testing process.\u003c/p\u003e\n\u003cp\u003eImplement Rapid Improvements:\nBased on the feedback, I prioritized quick wins that could immediately improve the user experience. We rolled out a patch that fixed the bugs and made some immediate adjustments to the navigation flow based on customer input.\nI also proposed and led a short-term project to create customizable interface options, allowing users to revert to a layout closer to the previous version if they preferred it.\u003c/p\u003e\n\u003cp\u003eProactive Communication:\nThroughout this process, I maintained open lines of communication with the affected customers, providing regular updates on our progress and the changes we were making. I also took the opportunity to thank them for their feedback and assured them that we were committed to addressing their concerns.\u003c/p\u003e\n\u003cp\u003ePost-Release Follow-Up:\nAfter the changes were implemented, I followed up with the customers to gather additional feedback and ensure the modifications addressed their issues. I also monitored the platform for further feedback to ensure the improvements were well-received.\u003c/p\u003e\n\u003cp\u003eResult:\nThe quick response and the adjustments we made led to a significant reduction in customer complaints, and the feedback shifted from negative to positive. The customizable interface option was particularly well-received, as it gave users more control over their experience. Our relationship with the customers improved, and they appreciated our responsiveness and willingness to adapt based on their needs.\u003c/p\u003e\n\u003cp\u003eReflection:\nThis experience reinforced the importance of actively listening to customer feedback and being agile in responding to it. By engaging directly with customers and being transparent about the steps we were taking, we were able to turn a negative situation into a positive one, ultimately enhancing the customer experience and strengthening our product.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. Tell me about a time when you had to deliver a product or feature under a tight deadline. How did you ensure it met customer expectations??\u003c/strong\u003e\nSituation: At my previous company, we had a client who requested a new feature for their application just weeks before their product launch. The feature was crucial for their marketing campaign, and they needed it delivered within an extremely tight deadline of two weeks.\u003c/p\u003e\n\u003cp\u003eTask: As the lead developer, my task was to ensure that we delivered a fully functional, high-quality feature on time, without compromising our existing development schedule.\u003c/p\u003e\n\u003cp\u003eAction: I started by breaking down the feature requirements into manageable tasks and prioritized them based on the client’s most critical needs. I then assembled a small team of developers and designers, ensuring everyone was clear on their responsibilities and the importance of meeting the deadline.\u003c/p\u003e\n\u003cp\u003eTo maximize efficiency, I implemented daily stand-up meetings to track progress, identify any roadblocks early, and make quick decisions. I also set up a continuous integration pipeline to automate testing and deployment, so that we could catch and fix bugs as early as possible.\u003c/p\u003e\n\u003cp\u003eThroughout the development process, I maintained close communication with the client to keep them updated on our progress and to manage their expectations. This also allowed us to get quick feedback on the feature’s implementation, ensuring we were aligned with their vision.\u003c/p\u003e\n\u003cp\u003eResult: We successfully delivered the feature on time, and it met the client’s expectations in terms of functionality and quality. The client was impressed with our ability to meet such a tight deadline without compromising on the end product. This experience not only strengthened our relationship with the client but also demonstrated our team’s ability to work efficiently under pressure.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4. Tell about a time you disagreed with your teamamt?\u003c/strong\u003e\nSituation:\nIn one of my previous projects, we were tasked with breaking down a monolithic application into microservices. The goal was to improve scalability and maintainability.\u003c/p\u003e\n\u003cp\u003eTask:\nMy role was to design the microservices architecture and ensure a smooth transition from the monolithic system. However, a teammate and I had a fundamental disagreement about how to approach this.\u003c/p\u003e\n\u003cp\u003eAction:\nMy teammate advocated for a \u0026ldquo;big bang\u0026rdquo; approach, where we would decompose the entire application at once and deploy all microservices simultaneously. They believed this would be more efficient and faster. I, on the other hand, favored an incremental approach. I suggested breaking down the application one component at a time, deploying each microservice individually, and ensuring that each one worked correctly before moving on to the next. I felt this would minimize risk and make it easier to identify and fix issues.\u003c/p\u003e\n\u003cp\u003eTo resolve the disagreement, we decided to:\nDiscuss Concerns: We sat down and outlined the pros and cons of both approaches. I highlighted the potential risks of a \u0026ldquo;big bang\u0026rdquo; deployment, such as the difficulty in debugging and the high impact of potential failures.\nRun Experiments: We agreed to conduct a proof-of-concept by splitting one part of the monolith into a microservice and deploying it. This would give us insights into the complexity and potential issues we might face.\nConsult with Stakeholders: We brought in our tech lead and a few other senior engineers to get their perspectives and advice. They supported the idea of an incremental approach given the complexity of our system.\u003c/p\u003e\n\u003cp\u003eResult:\nThe proof-of-concept was successful and demonstrated the benefits of an incremental approach. It allowed us to catch and resolve issues early, and it provided the team with valuable learning experiences. As a result, we adopted the incremental approach for the rest of the project.\u003c/p\u003e\n\u003cp\u003eIn the end, the project was a success. The incremental approach proved to be effective in managing risks and ensuring a smooth transition to microservices. This experience reinforced the importance of open communication, experimentation, and involving stakeholders in decision-making processes.\u003c/p\u003e\n","url":"https://karthikselvam.com/posts/2023/01/22/behavioral_questions/","image":"https://karthikselvam.com/photos/<no value>","banner_image":"https://karthikselvam.com/photos/<no value>","date_published":"22016-22-09T10:2222:00+00:00","date_modified":"22016-22-09T10:2222:00+00:00","author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"}}]}